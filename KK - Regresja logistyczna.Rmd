---
title: "Model predykcyjny - Framingham Heart Study"
author: "Kasper Kurzyński"
date: "26 05 2021"
output: 
  html_document:
    toc: TRUE
    toc_float: TRUE
    theme: "flatly"
    code_folding: hide
     
  
---
## Wstep

### Problem badawczy

   W dzisiejszym świecie, warunki i styl życia ludzi uległy radykalnej zmianie w stosunku do trybu, który reprezentowały wcześniejsze pokolenia. Ograniczona aktywność fizyczna, źle zbilansowana dieta oraz szeroko pojęte zanieczyszczanie środowiska wpłynęło na rozwój chorób cywilizacyjnych i sprawiło, że dotykają one co raz większą liczbę osób. Do najbardziej popularnych chorób cywilizacyjnych zaliczyć można depresję, choroby nowotworowe, otyłość, cukrzycę, astmę oskrzelową lub chorobę niedokrwienną serca.  

### Cel projektu
Modelowanie ryzyka wystąpienia choroby niedokrwiennej serca za pomocą regresji logistycznej

___
## Wczytanie potrzebnych bibliotek
```{r}

library("car") #funkcja vif()
library("ggplot2") #wykresy - funkcja ggplot()
library("pscl") #dopasowanie i predykcja
library("kableExtra") #tworzenie tabel
library("corrplot") #wizualizacja korelacji
library("pROC") #funkcje roc, auc
```
___
## Wczytanie oraz prezentacja danych
```{r}
heart_stats <- read.csv("C:/Users/Kasper/OneDrive/Pulpit/Modele parametryczne/framingham_data.csv")
colnames(heart_stats) <- c("Sex_male", "age", "currentSmoker", "cigsPerDay", "BPMeds", "prevalentStroke", 
                           "prevalentHyp", "diabetes", "sysBP", "diaBP", "heartRate_impt", "Glucose_impt",
                           "BMI_impt", "totChol_impt", "TenYearCHD")
head(heart_stats)
tail(heart_stats)

heart_stats$Sex_male <- as.factor(heart_stats$Sex_male)
heart_stats$currentSmoker <- as.factor(heart_stats$currentSmoker)
heart_stats$BPMeds <- as.factor(heart_stats$BPMeds)
heart_stats$diabetes <- as.factor(heart_stats$diabetes)
heart_stats$prevalentStroke <- as.factor(heart_stats$prevalentStroke)
heart_stats$prevalentHyp <- as.factor(heart_stats$prevalentHyp)
heart_stats$TenYearCHD <- as.factor(heart_stats$TenYearCHD)

heart_stats$heartRate_impt <- as.integer(heart_stats$heartRate_impt)
heart_stats$sysBP <- as.integer(heart_stats$sysBP)
heart_stats$diaBP <- as.integer(heart_stats$diaBP)
heart_stats$Glucose_impt <- as.integer(heart_stats$Glucose_impt)
heart_stats$BMI_impt <- as.integer(heart_stats$BMI_impt)
heart_stats$totChol_impt <- as.integer(heart_stats$totChol_impt)

str(heart_stats)
```


Dane zostały "zassane" z pliku csv i dla zmiennych jakościowych zmieniono typ danych z "char" na "factor". Zaprezentowane zostało również 6 pierwszych oraz 6 ostatnich rekordów w zbiorze danych.


### Podstawowe statystyki opisowe dla zmiennych ilościowych

```{r}
stats <- summary(heart_stats[,c(2,4,9,10,11,12,13,14)])
kbl(stats) %>%
  kable_styling(bootstrap_options = "hover", full_width = FALSE, position = "center")
```


Statystyki opisowe wskazują, że większość zmiennych cechuje się dużym rozstęptem (max - min). Np minimalna wartość poziomu glukozy we krwi to 40, natomiast maksymalna 394. Podobna sytuacja występuje w przypadku zmiennej CigsPerDay. W zbiorze danych znajdują się osoby, które nie palą papierosów oraz takie, które wypalają 70 papierosów dziennie. 


### Histogramy dla zmiennych ilościowych

```{r fig.height=20, fig.width=20} 
hist_age <- ggplot(data=heart_stats, aes(x=age)) + geom_histogram(binwidth = 5, color="Black", fill="Royalblue2") + theme(axis.title.x = element_text(color="gray23", size=25))

hist_cigsPerDay <- ggplot(data=heart_stats, aes(x=cigsPerDay)) + geom_histogram(binwidth = 5, color="Black", fill="seagreen3") + theme(axis.title.x = element_text(color="gray23", size=25))

hist_sysBP <- ggplot(data=heart_stats, aes(x=sysBP)) + geom_histogram(binwidth = 10,color="Black", fill="tomato3") + theme(axis.title.x = element_text(color="gray23", size=25))

hist_diaBP <- ggplot(data=heart_stats, aes(x=diaBP)) + geom_histogram(binwidth = 5,color="Black", fill="gold2") + theme(axis.title.x = element_text(color="gray23", size=25))

hist_heartRate_impt <- ggplot(data=heart_stats, aes(x=heartRate_impt)) + geom_histogram(binwidth = 10,color="Black", fill="Chocolate3") + theme(axis.title.x = element_text(color="gray23", size=25))

hist_Glucose_impt <- ggplot(data=heart_stats, aes(x=Glucose_impt)) + geom_histogram(binwidth = 15,color="Black", fill="aquamarine2") + theme(axis.title.x = element_text(color="gray23", size=25))

hist_BMI_impt <- ggplot(data=heart_stats, aes(x=BMI_impt)) + geom_histogram(binwidth = 5,color="Black", fill="purple3") + theme(axis.title.x = element_text(color="gray23", size=25))

hist_totChol_impt <- ggplot(data=heart_stats, aes(x=totChol_impt)) + geom_histogram(binwidth = 20,color="Black", fill="skyblue3") + theme(axis.title.x = element_text(color="gray23", size=25))

gridExtra::grid.arrange(hist_age,hist_cigsPerDay,hist_sysBP,hist_diaBP,
                        hist_heartRate_impt,hist_Glucose_impt,hist_BMI_impt,hist_totChol_impt)
```


Na histogramach można dostrzec przypadki odstające. Szczególnie wydoczne jest to dla zmiennych cigsPerDay, diaBP, sysBP lub Glucose_impt. Należy zbadać takie przypadki i zastanowić się nad ewentualnym usunięciem ich. 


### Wykresy pudełkowe dla wybranych zmiennych ilościowych

Istnienie przypadków odstających potwierdzają wykresy pudełkowe wykonane dla niektórych zmiennych. Na wykresach pudełkowych, przypadki odstające są oznaczone za pomocą kropek znajdujących się poza "wąsami" wykresu. 

```{r fig.height=20, fig.width=20}
par(mfrow=c(3,2))
box_age <- boxplot(heart_stats$age, main = "Wykres pudełkowy dla zmiennej age",
        ylab = "wiek",
        col ="royalblue2",
        border = "black", cex.main = 3)
box_cigs <- boxplot(heart_stats$cigsPerDay, main = "Wykres pudełkowy dla zmiennej cigsPerDay",
        ylab = "ilość wypalanych papierosów",
        col ="seagreen3",
        border = "black", cex.main = 3)
box_sysBP <- boxplot(heart_stats$sysBP, main = "Wykres pudełkowy dla zmiennej sysBP",
        ylab = "skurczowe ciśnienie krwi",
        col ="tomato3",
        border = "black", cex.main = 3)
box_BMI <- boxplot(heart_stats$BMI_impt, main = "Wykres pudełkowy dla zmiennej BMI_impt",
        ylab = "BMI",
        col ="purple3",
        border = "black", cex.main = 3)
box_totChol <- boxplot(heart_stats$totChol_impt, main = "Wykres pudełkowy dla zmiennej totChol_impt",
        ylab = "Poziom cholesterolu",
        col ="skyblue3",
        border = "black", cex.main = 3)

```

### Tabela zmiennych ilościowych zakodowanych jako {0,1}.

```{r}
names <- c("Sex_male", "currentSmoker", "BPMeds", "prevalentStroke", "prevalentHyp", "diabetes")
values_one <- c(0.43, 0.49, 0.03, 0.01, 0.31, 0.03)
values_zero <- c(0.57, 0.51, 0.97, 0.99, 0.69, 0.97) 
dummy_table <- data.frame(Zmienne=names, Udział_1=values_one, Udział_0=values_zero)
kbl(dummy_table ) %>%
  kable_styling(bootstrap_options = "hover", full_width = FALSE, position = "center")
```

W przypadku zmiennych takich jak Sex_male i currentSmoker udział przypadków zakodowanych jako "1" i "0" jest zbliżony do równomiernego. Inaczej sytuacja klaruje się dla zmiennych BPMeds, prevalentStroke i diabetes. Większość przypadków dla tych zmiennych jest oznaczona jako 0.


### Wykresy słupkowe dla zmiennych ilościowych zakodowanych jako {0,1}
```{r fig.height=20, fig.width=20}
bar_sexmale <- ggplot(data=heart_stats, aes(x=Sex_male, fill=Sex_male)) + geom_bar() + theme(axis.title.x = element_text(color="gray23", size=
25))
bar_currentsmoker <- ggplot(data=heart_stats, aes(x=currentSmoker, fill=currentSmoker)) + geom_bar() + theme(axis.title.x = element_text(color="gray23", size=
25))
bar_BPMeds <- ggplot(data=heart_stats, aes(x=BPMeds, fill=BPMeds)) + geom_bar() + theme(axis.title.x = element_text(color="gray23", size=
25))
bar_prevalentStroke <- ggplot(data=heart_stats) + geom_bar(aes(x=prevalentStroke, fill=prevalentStroke)) + theme(axis.title.x = element_text(color="gray23", size=
25))
bar_prevalentHyp <- ggplot(data=heart_stats, aes(x=prevalentHyp, fill=prevalentHyp)) + geom_bar() + theme(axis.title.x = element_text(color="gray23", size=
25))
bar_diabetes <- ggplot(data=heart_stats, aes(x=diabetes, fill=diabetes)) + geom_bar() + theme(axis.title.x = element_text(color="gray23", size=
25))
gridExtra::grid.arrange(bar_sexmale,bar_currentsmoker,bar_BPMeds,
                        bar_prevalentStroke, bar_prevalentHyp, bar_diabetes)
```

### Wykres słupkowy dla zmiennej objaśnianej.
```{r}
ggplot(data=heart_stats, aes(x=TenYearCHD, fill=TenYearCHD)) + geom_bar() + theme(axis.title.x = element_text(color="gray23", size=
25))
table(heart_stats$TenYearCHD)/nrow(heart_stats)
```

```{r}
corrMatrix <- matrix(cor(heart_stats[,c(2,4,9,10,11,12,13,14)]), 8,8)
rownames(corrMatrix) <- c("age", "cigsPerDay", "sysBP", "diaBP", "heartRate_impt", "Glucose_impt", "BMI_impt", "totChol_impt")
colnames(corrMatrix) <- c("age","cigsPerDay","sysBP", "diaBP", "heartRate_impt", "Glucose_impt", "BMI_impt", "totChol_impt")
corrMatrix_df <- data.frame(corrMatrix)
```

### Macierz korelacji dla zmiennych ilosciowych
```{r}

  kbl(corrMatrix_df) %>%
  kable_styling(bootstrap_options = "responsive", full_width = FALSE, position = "center")
```
___
Wśród zmiennych objaśniających ilościowych nie występują znaczące korelacje. Większość współczynników korelacji ukształtowała się na poziomie <0.3, -0.3>. Jedynie zmienne SysBP i diaBP są ze sobą silnie skorelowane. Współczynnik korelacji dla tej pary zmiennych wynosi 0.78. Być może będzie to podstawą do usunięcia jednej z tych zmiennych z dalszej analizy.


### Testy sprawdzające zależność między zmiennymi dychotomicznymi
```{r}
wynik1 <- chisq.test(heart_stats$BPMeds, heart_stats$prevalentStroke)
wynik2 <- chisq.test(heart_stats$currentSmoker, heart_stats$Sex_male)
wynik3 <- chisq.test(heart_stats$currentSmoker, heart_stats$BPMeds)
wynik4 <- chisq.test(heart_stats$Sex_male, heart_stats$prevalentHyp)
wynik5 <- chisq.test(heart_stats$diabetes, heart_stats$Sex_male)
vektor_chi <- c(wynik1$statistic, wynik2$statistic, wynik3$statistic, wynik4$statistic, wynik5$statistic)
vektor_p <- c(wynik1$p.value, wynik2$p.value, wynik3$p.value, wynik4$p.value, wynik5$p.value)
df <- data.frame(Statystyka_Chi_Kwadrat=vektor_chi, P_value=vektor_p)
rownames(df) <- c("BPMeds * prevalentStroke", "currentSmoker * Sex_male", "currentSmoker * BPMeds", "Sex_male * prevalentHyp", "diabetes * Sex_male")
df
```
___
Zmienne BPMeds i prevalent stroke, currentSmoker i Sex_male oraz currentSmoker i BPMeds okazały się wzajemnie zależne, ponieważ wartość p-value jest niższa niż zakładany poziom istotności 5% i należy odrzucić hipotezę zerową. Z drugiej strony zmienne Sex_male i prevalentHyp oraz diabetes i Sex_male nie wykazują zależności. W ich przypadku nie istnieją podstawy do odrzucenia hipotezy zerowej. 


### Wykres korelacji
```{r fig.height=10, fig.width=10}
col1 <-  colorRampPalette(c("deepskyblue", "deepskyblue1", "deepskyblue2", "deepskyblue3", "deepskyblue4", "darkseagreen", "coral",
 "coral1", "coral2", "coral3"))

corrplot(corrMatrix, method = "color", col = col1(100))
```
Na powyższym wykresie raz jeszcze można zobaczyć korelacje pomiędzy zmiennymi ilościowymi, które biorą udział w badaniu. Do wizualizacji korelacji został wykorzystany "corrplot".

___
## Podział zbioru na uczący i testowy.
```{r}
set.seed(100) 
n <- nrow(heart_stats)
liczby_dzielace <- sample(c(1:n), round(0.8*n), replace = FALSE)

heart_stats_train <- heart_stats[liczby_dzielace,]
heart_stats_test <- heart_stats[-liczby_dzielace,]

table(heart_stats_train$TenYearCHD)/nrow(heart_stats_train)
table(heart_stats_test$TenYearCHD)/nrow(heart_stats_test)

```

Do budowy modelu regresji logistycznej należało dokonać zabieg podziału zbioru danych na zbiór uczący i testowy. Został on podzielony w proporcjach 80:20, co oznacza, że 80% obserwacji znalazło się w zbiorze uczącym, natomiast pozostałe 20% w zbiorze testowym. W zbiorze uczącym dla zmiennej zależnej TenYearCHD "0" stanowią 0.85026% wszystkich obserwacji, natomiast "1" - 0.149731%. Z kolei w zbiorze testowym udział "0" wynosi 0.8434886%, natomiast udział "1" to 0.1565114%. 

___
## Oszacowanie modelu regresji logistycznej
```{r}
logit <- glm(TenYearCHD ~ . ,data=heart_stats_train, family=binomial(link=logit))
summary(logit)
probit <- glm(TenYearCHD ~ . ,data=heart_stats_train, family=binomial(link=probit))
summary(probit)
```

**Wnioski**

Dla **modelu logitowego** testy statystyczne dla poszczególnych parametrów beta pokazały, że nie wszystkie parametry sa istotne statystycznie (<0,05). Zmienne: currentSmoker, BPMeds, prevalentStroke, prevalentHyp, diabetes, diaBP, heartRate_impt, BMI_impT oraz totChol_impt posiadają wartość p-value wyższą niż zakładany 5% poziom istotności, a więc należy wyłączyć je z dalszej analizy. Takie wyniki mogą być spowodowane wysokimi korelacjami między tymi zmiennymi. Do dalszej analizy zostaną wykorzystane pozostałe zmienne, których wartość p-value była niższa niż umowne 5%. Kryterium informacyjne Akaike w tym modelu wyniosło 2533.8.

Dla **modelu probitowego** testy statystyczne dla poszczególnych parametrów beta pokazały, że nie wszystkie parametry sa istotne statystycznie (<0,05). Zmienne: currentSmoker, BPMeds, prevalentStroke, prevalentHyp, diabetes, diaBP, heartRate_impt, BMI_impT oraz totChol_impt posiadają wartość p-value wyższą niż zakładany 5% poziom istotności, a więc należy wyłączyć je z dalszej analizy. Takie wyniki mogą być spowodowane wysokimi korelacjami między tymi zmiennymi. Do dalszej analizy zostaną wykorzystane pozostałe zmienne, których wartość p-value była niższa niż umowne 5%. Kryterium informacyjne Akaike w tym modelu wyniosło 2533.

Dla obywdu modeli liczba istotnie statystych zmiennych jest taka sama, natomiast kryterium informacyjne Akaike w modelu logitowych jest nieznacznie wyższe (o 0.8). Z tego powodu do dalszej analizy warto wybrać model logitowy, ponieważ jest lepszy w kwestii interpretacji parametrów. 

### Sprawdzenie założenia o braku współliniowości zmiennych objaśniających za pomocą miary VIF (Variance Inflation Factor).

```{r}
vif(logit)
vif(probit)
```

Miary VIF obliczone dla modelu logitowego znajdują się w górnej cześcim natomiast dla modelu probitowego w dolnej. Zmienne nie są współliniowe. Zgodnie z ogólnie przyjętą zasadą, umowną granicą występowania współliniowości jest VIF > 5. Najwyższa wartość miary VIF zaobserwowano dla zmiennej sysBP, wynosi 3.6.

___
## Modele po redukcji liczby zmiennych objaśniających
```{r}
logit1 <- glm(TenYearCHD ~ Sex_male+age+cigsPerDay+sysBP+Glucose_impt, data=heart_stats_train, family=binomial(link=logit))
summary(logit1)

probit1 <- glm(TenYearCHD ~ Sex_male+age+cigsPerDay+sysBP+Glucose_impt, data=heart_stats_train, family=binomial(link=probit))
summary(probit1)
```

**Wnioski**
Modele po redukcji zmiennych posiadaja teraz wszystkie parametry istotne statystycznie. Dla **modelu logitowego** Kryterium Akaike spadlo z 2533.8 na 2523.4. Z kolei dla **modelu probitowego** z 2533 na 2522.8.

___
## Porównanie dobroci dopasowania modelow logit/probit
```{r}
porownanie_modelow <- function(model) {
  kryterium_AIC <- c(model$aic)
  McFadden<-pR2(model)[4]
  Cragg_Uhler<-pR2(model)[6]
  ocena <- data.frame(kryterium_AIC, McFadden, Cragg_Uhler)
  return(ocena)
}
wyniki_oceny_logit_probit <- rbind(model_logit=porownanie_modelow(logit1), model_probit=porownanie_modelow(probit1))
wyniki_oceny_logit_probit
```

**Wnioski**
Minimalnie lepszym modelem jest **model probitowy**, ponieważ dla niego kryterium informacyjne akaike (AIC) jest minimalnie mniejsze niz dla modelu logitowego, a miary dopasowania pseudo r2 sa minimalnie wieksze niz dla modelu logitowego. Jednakże ze wzgledu na minimalna roznice w jakosci, interpretacji poddamy model logitowy, ze wzgledu na trudnosci w interpretacji modelu probitowego.

___
## Interpretacja modelu logitowego
```{r}
wsp_macierz <- matrix(logit1$coefficients)
colnames(wsp_macierz) <- "Współczynnik"
rownames(wsp_macierz) <- c("Intercept", "Sex_male", "age", "cigsPerDay", "sysBP", "Glucose_impt")
wsp_macierz
interpretacja <- c(exp(logit1$coefficients[2]),exp(logit1$coefficients[3]),
          exp(logit1$coefficients[4]), exp(logit1$coefficients[5]),
          exp(logit1$coefficients[6]))
int_matrix <- matrix(interpretacja)
colnames(int_matrix) <- "Interpretacja"
rownames(int_matrix) <- c("Sex_male", "age", "cigsPerDay", "sysBP", "Glucose_impt")
int_matrix

```

**Postac modelu:** `ln(p/1-p)= -8.7048 +  0.4899*Sex_male + 0.0681*age + 0.0238*cigsPerDay + 0.0162*sysBP + 0.0094*Glucose_impt`

Wartość exp(b0) jest interpretowana jako szansa zdarzenia w grupie refenrencyjnej, czyli takiej, dla której wartości X przyjmują 0. W powyższym modelu taka interpretacja nie ma sensu, ponieważ nie ma osób które posiadają zerowe skurczowe ciśnienie krwi oraz ich poziom glukozy jest równy 0. 
`exp(b0) = exp(-8.7048)=0,0002`

Co natomiast mówią ilorazy szans dla poszczególnych zmiennych?

**Współczynnik przy Sex_male**
- Szansa wystapienia choroby niedokrwiennej serca u mezczyzn jest o 63,22% większa niż u kobiet, przy stałych wartościach pozostałych zmiennych, czyli dla osob w tym samym wieku, takiej samej liczbie wypalanych papierosow w ciągu dnia, o takim samym skurczowym ciśnieniu krwi oraz poziomie glukozy.

**Współczynnik przy age**
- Jeżeli wiek wzrośnie o jednostkę, to ryzyko wystapienia choroby niedokrwiennej serca wzrośnie o 7,05% przy stałych wartościach pozostałych zmiennych.

**Współczynnik przy cigsPerDay**
- Jeżeli liczba wypalanych papierosów dziennie wzrośnie o jednostkę, to ryzyko wystąpienia choroby niedokrwiennej serca wzrośnie o 2,4%, przy stałch wartościach pozostałych zmiennych.

**Współczynnik przy sysBP**
- Jeżeli skurczowe ciśnienie krwi wzrośnie o jednostkę, to ryzyko wystąpienia choroby niedokrwiennej serca wzrośnie o 1,6%, przy stałch wartościach pozostałych zmiennych.

**Współczynnik przy Glucose_impt**
- Jeżeli poziom glukozy wzrośnie o jednostkę, to ryzyko wystąpienia choroby niedokrwiennej serca wzrośnie o 0,95%, przy stałch wartościach pozostałych zmiennych.

___
## Porównanie jakości predykcji modeli logit i probit
### Tablice trafnosci dla p=0.5

**Tablica trafności dla modelu logitowego - dla proby uczacej**
```{r}
p<-0.5
tab_traf <- data.frame(obserwowane=logit1$y, przewidywane=ifelse(logit1$fitted.values>p, 1, 0))
table(tab_traf)
```

**Tablica trafności dla modelu probitowego - dla proby uczacej**
```{r}
p<-0.5
tab_traf <- data.frame(obserwowane=probit1$y, przewidywane=ifelse(probit1$fitted.values>p, 1, 0))
table(tab_traf)
```

**Tablica trafności dla modelu logitowego - dla proby testowej**
```{r}
p<-0.5
tab_traf <- data.frame(obserwowane=heart_stats_test$TenYearCHD, przewidywane=ifelse(predict(logit1, heart_stats_test, type = 'response')>p, 1, 0))
table(tab_traf)
```

**Tablica trafności dla modelu probitowego - dla proby testowej**
```{r}
p<-0.5
tab_traf <- data.frame(obserwowane=heart_stats_test$TenYearCHD, przewidywane=ifelse(predict(probit1, heart_stats_test, type = 'response')>p, 1, 0))
table(tab_traf)
```

### Tablice trafnosci dla p = proporcja z proby

**Tablica trafności dla modelu logitowego - dla proby uczacej**
```{r}
p <- table(heart_stats_train$TenYearCHD) [2]/nrow(heart_stats_train)
tab_traf <- data.frame(obserwowane=logit1$y, przewidywane=ifelse(logit1$fitted.values>p, 1, 0))
table(tab_traf)
```

**Tablica trafności dla modelu probitowego - dla proby uczacej**
```{r}
p <- table(heart_stats_train$TenYearCHD) [2]/nrow(heart_stats_train)
tab_traf <- data.frame(obserwowane=probit1$y, przewidywane=ifelse(probit1$fitted.values>p, 1, 0))
table(tab_traf)
```


**Tablica trafności dla modelu logitowego - dla proby testowej**
```{r}
p <- table(heart_stats_test$TenYearCHD) [2]/nrow(heart_stats_test)
tab_traf <- data.frame(obserwowane=heart_stats_test$TenYearCHD, przewidywane=ifelse(predict(logit1, heart_stats_test, type = 'response')>p, 1, 0))
table(tab_traf)
```

**Tablica trafności dla modelu probitowego - dla proby testowej**
```{r}
p <- table(heart_stats_test$TenYearCHD) [2]/nrow(heart_stats_test)
tab_traf <- data.frame(obserwowane=heart_stats_test$TenYearCHD, przewidywane=ifelse(predict(probit1, heart_stats_test, type = 'response')>p, 1, 0))
table(tab_traf)
```
___
## Ocena jakości predykcji (trafności prognoz)

**Dla p=0.5**

```{r}
miary_pred_uczacy <- function(model, Y, p=0.5) {
  tab <- table(obserwowane=heart_stats_train$TenYearCHD, przewidywane=ifelse(predict(model, heart_stats_train, type = 'response')>p, 1, 0))
  ACC <- (tab[1,1]+tab[2,2])/sum(tab)
  ER <- (tab[1,2]+tab[2,1])/sum(tab)
  SENS <- tab[2,2]/(tab[2,2]+tab[2,1])
  SPEC <- tab[1,1]/(tab[1,1]+tab[1,2])
  PPV  <- tab[2,2]/(tab[2,2]+tab[1,2])
  NPV  <- tab[1,1]/(tab[1,1]+tab[2,1])
  miary <- data.frame(ACC, ER, SENS, SPEC, PPV, NPV)
  return(miary)
}

miary_pred_testowy <- function(model, Y, p=0.5) {
  tab <- table(obserwowane=heart_stats_test$TenYearCHD, przewidywane=ifelse(predict(model, heart_stats_test, type = 'response')>p, 1, 0))
  ACC <- (tab[1,1]+tab[2,2])/sum(tab)
  ER <- (tab[1,2]+tab[2,1])/sum(tab)
  SENS <- tab[2,2]/(tab[2,2]+tab[2,1])
  SPEC <- tab[1,1]/(tab[1,1]+tab[1,2])
  PPV  <- tab[2,2]/(tab[2,2]+tab[1,2])
  NPV  <- tab[1,1]/(tab[1,1]+tab[2,1])
  miary <- data.frame(ACC, ER, SENS, SPEC, PPV, NPV)
  return(miary)
}
wyniki_miary_pred <- rbind(model_logit_testowy=miary_pred_testowy(model=logit1, Y=heart_stats_test$TenYearCHD, p=0.5), model_logit_uczacy=miary_pred_uczacy(model=logit1, Y=heart_stats_train$TenYearCHD, p=0.5),model_probit_testowy=miary_pred_testowy(model=probit1, Y=heart_stats_test$TenYearCHD, p=0.5), model_probit_uczacy=miary_pred_uczacy(model=probit1, Y=heart_stats_train$TenYearCHD, p=0.5))
wyniki_miary_pred
```
**Wnioski**

Wykorzystując punkt odcięcia p = 0.5 zliczeniowy R^2 (ACC), czyli udział liczby trafnie sklasyfikowanych jednostek w ogólnej liczbie jednostek wynosi dla każdego modelu w przybliżeniu 0.85. Z drugiej strony, wskaźnik błędu ER, który wskazuję na udział liczby źle sklasyfikowanych jednostek w ogólnej liczbie jednostek wyniósł w przybliżeniu 0.14 - 0.15 dla rozpatrywanych modeli. Obydwa wyniki są zadowalające i można byłoby uznać taki model za odpowiedni. Jednakże uwagę zwraca również ocena SENS i SPEC, która oznacza odpowiednio czułość i swoistość. Czułość jest to udział liczby trafnie oszacowanych 1 w liczbie wszystkich obserwowanych 1, natomiast swoistość działa analogicznie, tylko że dla 0. W modelu logitowym, który będzie rozpatrywany miary te wyniosły SENS = 0.069 i 
SPEC = 0.992. W kontekście rozpatrywanego zjawiska nie są to zadowalające wyniki, gdyż oznacza to, że tylko 0.7% osób z ryzykiem zachorowania na chorobę niedokrwienną serca jest poprawnie klasyfikowanych. W celu poprawienia tego wyniku należy wykorzystać wartość odcinającą, która wynika z proporcji z próby i wynosi p = 0.148.


**Dla p=proporcja z próby**

```{r}
miary_pred_uczacy <- function(model, Y, p) {
  tab <- table(obserwowane=heart_stats_train$TenYearCHD, przewidywane=ifelse(predict(model, heart_stats_train, type = 'response')>p, 1, 0))
  ACC <- (tab[1,1]+tab[2,2])/sum(tab)
  ER <- (tab[1,2]+tab[2,1])/sum(tab)
  SENS <- tab[2,2]/(tab[2,2]+tab[2,1])
  SPEC <- tab[1,1]/(tab[1,1]+tab[1,2])
  PPV  <- tab[2,2]/(tab[2,2]+tab[1,2])
  NPV  <- tab[1,1]/(tab[1,1]+tab[2,1])
  miary <- data.frame(ACC, ER, SENS, SPEC, PPV, NPV)
  return(miary)
}

miary_pred_testowy <- function(model, Y, p) {
  tab <- table(obserwowane=heart_stats_test$TenYearCHD, przewidywane=ifelse(predict(model, heart_stats_test, type = 'response')>p, 1, 0))
  ACC <- (tab[1,1]+tab[2,2])/sum(tab)
  ER <- (tab[1,2]+tab[2,1])/sum(tab)
  SENS <- tab[2,2]/(tab[2,2]+tab[2,1])
  SPEC <- tab[1,1]/(tab[1,1]+tab[1,2])
  PPV  <- tab[2,2]/(tab[2,2]+tab[1,2])
  NPV  <- tab[1,1]/(tab[1,1]+tab[2,1])
  miary <- data.frame(ACC, ER, SENS, SPEC, PPV, NPV)
  return(miary)
}
p <- table(heart_stats$TenYearCHD) [2]/nrow(heart_stats)
wyniki_miary_pred <- rbind(model_logit_testowy=miary_pred_testowy(model=logit1, Y=heart_stats_test$TenYearCHD, p), model_logit_uczacy=miary_pred_uczacy(model=logit1, Y=heart_stats_train$TenYearCHD, p),model_probit_testowy=miary_pred_testowy(model=probit1, Y=heart_stats_test$TenYearCHD, p), model_probit_uczacy=miary_pred_uczacy(model=probit1, Y=heart_stats_train$TenYearCHD, p))
wyniki_miary_pred
```
**Wnioski**

Po zmianie wartości odcinającej miary oceny jakości predykcji uległy zmianom dla wszystkich rozpatrywanych modeli. Przede wszystkim pogorszyła się wartość ACC i tym samym zwiększył się wskaźnik błędu ECC. Jednakże, warto zaznaczyć, że znacząco zwiększyła się czułośc. Obecnie wynosi 0.63 dla modelu logitowego dla próby testowej i 0.68 dla próby uczącej. Taki wynik jest już bardziej satysfakcjonujący, ponieważ jest to jednoznacznie z tym, że 63% osób zagrożonych chorobą niedokrwienną serca jest poprawnie klasyfikowane. 

___
## Krzywe ROC dla modelu logitowego i probitowego

```{r fig.height=10, fig.width=15}
rocobj1 <- roc(heart_stats_train$TenYearCHD, logit1$fitted.values)
rocobj1_t <- roc(heart_stats_test$TenYearCHD, predict(logit1, heart_stats_test, type = "response"))

rocobj2 <- roc(heart_stats_train$TenYearCHD, probit1$fitted.values)
rocobj2_t <- roc(heart_stats_test$TenYearCHD, predict(probit1, heart_stats_test, type = "response"))

rocl_train <- ggroc(rocobj1, legacy.axes = TRUE)+
  ggtitle("Krzywa ROC dla modelu logitowego - zbiór uczący") +
  geom_segment(aes(x = 0, xend = 1, y = 0, yend = 1), color="skyblue3")+
  geom_hline(aes(yintercept=1), lty=2, color="coral1")+
  geom_hline(aes(yintercept=0), lty=2, color="coral1")+
  geom_vline(aes(xintercept=1), lty=2, color="coral1")+
  geom_vline(aes(xintercept=0), lty=2, color="coral1")+
  theme_minimal()

rocl_test <- ggroc(rocobj1_t, legacy.axes = TRUE)+
  ggtitle("Krzywa ROC dla modelu logitowego - zbiór testowy") +
  geom_segment(aes(x = 0, xend = 1, y = 0, yend = 1), color="firebrick3")+
  geom_hline(aes(yintercept=1), lty=2, color="palegreen3")+
  geom_hline(aes(yintercept=0), lty=2, color="palegreen3")+
  geom_vline(aes(xintercept=1), lty=2, color="palegreen3")+
  geom_vline(aes(xintercept=0), lty=2, color="palegreen3")+
  theme_minimal()

rocp_train <- ggroc(rocobj2, legacy.axes = TRUE)+
  ggtitle("Krzywa ROC dla modelu probitowego - zbiór uczący") +
  geom_segment(aes(x = 0, xend = 1, y = 0, yend = 1), color="limegreen")+
  geom_hline(aes(yintercept=1), lty=2, color="dodgerblue3")+
  geom_hline(aes(yintercept=0), lty=2, color="dodgerblue3")+
  geom_vline(aes(xintercept=1), lty=2, color="dodgerblue3")+
  geom_vline(aes(xintercept=0), lty=2, color="dodgerblue3")+
  theme_minimal()

rocp_test <- ggroc(rocobj2_t, legacy.axes = TRUE)+
  ggtitle("Krzywa ROC dla modelu probitowego - zbiór testowy") +
  geom_segment(aes(x = 0, xend = 1, y = 0, yend = 1), color="purple3")+
  geom_hline(aes(yintercept=1), lty=2, color="gold3")+
  geom_hline(aes(yintercept=0), lty=2, color="gold3")+
  geom_vline(aes(xintercept=1), lty=2, color="gold3")+
  geom_vline(aes(xintercept=0), lty=2, color="gold3")+
  theme_minimal()

gridExtra::grid.arrange(rocl_train, rocl_test, rocp_train, rocp_test)
```
Na powyższych wykresach zostały zaprezentowane krzywe ROC dla modeli logitowych oraz probitowych zarówno dla danych uczących jak i testowych. Na krzyżej ROC można znaleźć więcej informacji niż podczas analizowania tablicy trafności, ponieważ przedstawia ona siłę predykcji dla wszystkich możliwych punktów odcięcia p*.

___
### Pole powierzchni pod krzywą ROC
```{r}
pole_AUC_logit_testowy<-as.numeric(auc(heart_stats_test$TenYearCHD, predict(logit1, heart_stats_test, type = "response")))
pole_AUC_probit_testowy<-as.numeric(auc(heart_stats_test$TenYearCHD, predict(probit1, heart_stats_test, type = "response")))
pole_AUC_logit_uczacy<-as.numeric(auc(heart_stats_train$TenYearCHD, logit1$fitted.values))
pole_AUC_probit_uczacy<-as.numeric(auc(heart_stats_train$TenYearCHD, probit1$fitted.values))

pole_AUC <- rbind(pole_AUC_logit_uczacy, pole_AUC_logit_testowy, pole_AUC_probit_uczacy, pole_AUC_probit_testowy)
pole_AUC
```
___
Pole pod krzywą ROC przyjmuje wartości z przediału od 0 do 1. Określa ono zdolność testu do rozgraniczenia wyników prawidłowych i nieprawidłowych. Podczas tworzenia modelu powinno zależeć na tym, aby pole pod przywą ROC było jak największe, ponieważ tym samym zwiększa się moc predykcyjna takiego modelu. Porównując cztery obliczone pola pod krzywą ROC, największa wartość została osiągnięta dla modelu Logit na danych uczących i wynosi ona 0.7312191. W oparciu o dane testowe, również dla modelu logitowego wartość ta jest wyższa i wynosi 0.7131566.


### Wskaznik Gini'ego
```{r}
Gini_logit_testowy <- 2*pole_AUC_logit_testowy-1
Gini_probit_testowy <- 2*pole_AUC_probit_testowy-1
Gini_logit_uczacy <- 2*pole_AUC_logit_uczacy-1
Gini_probit_uczacy <- 2*pole_AUC_probit_uczacy-1
GINI <- rbind(Gini_logit_uczacy, Gini_logit_testowy, Gini_probit_uczacy, Gini_probit_testowy)
GINI
```
___
W przypadku wskaźnika Gini'ego, który jest powiązany z polem pod krzywą ROC również najwyższe wartości przypadły modelowi logitowemu, zarówno dla danych uczących jak i testowych.

___
## PODSUMOWANIE I WNIOSKI
W procesie walki z chorobami serca niezwykle ważna jest odpowiednia diagnoza i zapobieganie wystąpieniu takich chorób już we wczesnym etapie rozwoju. Z tego powodu podjęty przez nas temat uznany być może jako istotny i ważny w kontekście polepszenia ochrony zdrowia w populacji. Za pomocą regresji logistycznej udało się oszacować model, który w pewnym stopniu mógłby okazać się pomocny dla ludzi z ryzykiem wystąpienia u nich choroby niedokrwiennej serca. Oszacowany model wykazał, że porównując obydwie płcie, bardziej narażeni są mężczyźni i szansa na to, że wystąpi u nich omawiana choroba jest aż o 63% większa niż w przypadku kobiet. Kolejnym czynnikiem, który zwiększa ryzyko wystapienia choroby niedokrwiennej serca jest wiek. Model wykazał, że każdy kolejny rok życia powoduje, że to ryzyko wzrasta o 7,05%. Ludzie palący, który zwiększą ilość dziennie wypalanych papierosów sprawią, że w ich przypadku szansa na zachorowanie wzrośnie o 2,4%. Ryzyko wystąpienia choroby niedokrwiennej serca zwiększa się o 1,6%, gdy skurczowe ciśnienie krwi wzrośnie o jednostkę. W przypadku poziomu glukozy szansa na zachorowanie na chorobę niedokrwienną serca zwiększa się o 0,95%, kiedy ten poziom wzrasta o jednostkę, więc wzrost poziomu glukozy najmniej przyczynia się do choroby niedokrwiennej serca. Powyższe dane pozwalają na dojście do konkluzji, że szczególnie mężczyźni wraz z wiekiem powinni częściej poddawać się badaniom serca. Natomiast w przypadku obydwu płci zalecane jest ograniczanie palenie, a najlepiej definitywne zakończenie z tym nałogiem.

